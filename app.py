import streamlit as st
import json
import os
import tempfile
import numpy as np
from PIL import Image, ImageDraw
from google import genai
# Importa√ß√£o corrigida do MoviePy para resolver o ModuleNotFoundError
import moviepy.editor as mp_editor
from edge_tts import communicate # Biblioteca para Text-to-Speech

# =========================================================================
# 1. FUN√á√ïES DE GERA√á√ÉO (IA E TTS)
# =========================================================================

@st.cache_data
def create_placeholder_image(scene_id, text, width=1280, height=720):
    """
    Cria uma imagem de placeholder colorida no diret√≥rio tempor√°rio
    para simular o asset de imagem gerado por IA.
    """
    try:
        # Cria uma imagem colorida baseada no ID da cena para diferencia√ß√£o
        hue = (scene_id * 50) % 360  # Altera a tonalidade com base no ID
        # Converte HSL para RGB (Streamlit Cloud usa Python, n√£o CSS)
        
        # Cria a imagem PIL
        img = Image.new('RGB', (width, height), "rgb(50, 50, 100)")
        draw = ImageDraw.Draw(img)

        # Configura√ß√µes de texto
        font_color = (255, 255, 255)
        text_to_display = f"CENA {scene_id} - Imagem IA Placeholder\n\n{text}"
        
        # Adiciona o texto (usando a fonte padr√£o)
        # O ImageDraw √© limitado em Streamlit Cloud, ent√£o usamos uma cor de fundo s√≥lida
        # para garantir a legibilidade.
        draw.text((50, 50), text_to_display, font=font_color) 

        # Salva o arquivo temporariamente
        temp_img_path = os.path.join(tempfile.gettempdir(), f"cena_{scene_id}.png")
        img.save(temp_img_path)
        return temp_img_path
    except Exception as e:
        st.error(f"Erro ao criar imagem placeholder: {e}")
        return None


def generate_tts_audio(scene_id, text_narration, voice="pt-BR-FranciscaNeural"):
    """
    Gera o arquivo de √°udio (narra√ß√£o) usando Edge-TTS e retorna o caminho e a dura√ß√£o.
    """
    temp_audio_path = os.path.join(tempfile.gettempdir(), f"audio_cena_{scene_id}.mp3")
    
    try:
        # Cria o comunicador TTS
        comm = communicate(text_narration, voice)
        
        # Salva o √°udio no arquivo tempor√°rio
        with open(temp_audio_path, "wb") as file:
            # O Edge-TTS retorna um gerador de chunks de √°udio
            for chunk in comm:
                if chunk[0] == 2: # O tipo 2 √© o dado de √°udio
                    file.write(chunk[1])
        
        # Usa o MoviePy para determinar a dura√ß√£o exata do √°udio
        # Usamos o mp_editor pois √© a importa√ß√£o corrigida
        audio_clip = mp_editor.AudioFileClip(temp_audio_path)
        duration = audio_clip.duration
        audio_clip.close() 

        return temp_audio_path, duration
    
    except Exception as e:
        st.error(f"Erro ao gerar √°udio TTS para a cena {scene_id}: {e}")
        return None, 0.0


def generate_script_and_prompts(idea_central, gemini_api_key):
    """
    Usa a API do Gemini para gerar um roteiro estruturado no formato JSON.
    """
    
    # 1. Configura√ß√£o da API
    try:
        client = genai.Client(api_key=gemini_api_key)
    except Exception as e:
        st.error(f"Erro de inicializa√ß√£o da API Gemini: {e}. Verifique a chave em 'st.secrets'.")
        return {"error": "Falha na inicializa√ß√£o da API."}


    # 2. PROMPT DE ENGENHARIA (O cora√ß√£o da automa√ß√£o)
    prompt_instruction = f"""
    Voc√™ √© um roteirista profissional de v√≠deos curtos (YouTube Shorts) no estilo "Motivacional" ou "Curiosidades".
    O v√≠deo final deve ter no m√°ximo 45 segundos.

    A IDEIA CENTRAL do v√≠deo √©: "{idea_central}".

    Sua resposta deve ser estruturada em 3 a 5 Cenas, seguindo o FORMATO JSON estrito.
    N√£o adicione texto introdut√≥rio, explica√ß√µes ou qualquer conte√∫do fora do JSON.

    Para cada cena, gere TR√äS campos:
    1. "texto_narra√ß√£o": O texto exato (curto e envolvente) que ser√° falado.
    2. "duracao_segundos": O tempo de dura√ß√£o exato em segundos (entre 3.0 e 10.0) para esta cena.
    3. "prompt_imagem_ingles": Um prompt em INGL√äS, altamente descritivo e pronto para ser usado em um gerador de Imagens por IA (ex: Midjourney ou Stable Diffusion). O prompt deve ser ultra-realista e esteticamente agrad√°vel, e refletir exatamente o texto de narra√ß√£o.

    EXEMPLO DO FORMATO JSON (Use este modelo exatamente):

    {{
      "titulo_sugerido": "T√≠tulo chamativo aqui.",
      "cenas": [
        {{
          "id": 1,
          "texto_narra√ß√£o": "A jornada de mil milhas come√ßa com um √∫nico passo.",
          "duracao_segundos": 4.5,
          "prompt_imagem_ingles": "Cinematic shot of a lone traveler standing on a misty mountain path at sunrise, deep focus, epic, 8k, photorealistic."
        }},
        {{
          "id": 2,
          "texto_narra√ß√£o": "O medo de falhar √© o que realmente nos impede de voar.",
          "duracao_segundos": 6.0,
          "prompt_imagem_ingles": "Conceptual art, a shadow figure holding a large broken cage, volumetric lighting, digital painting, dramatic."
        }}
      ]
    }}
    """
    
    # 3. Chamada √† API
    try:
        with st.spinner('Gerando roteiro estruturado com Gemini...'):
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt_instruction,
                config={"response_mime_type": "application/json"}
            )
        
        # 4. Retorno
        # O Streamlit Cloud pode adicionar caracteres de formata√ß√£o; tentamos limpar
        json_text = response.text.strip().lstrip('```json').rstrip('```')
        return json.loads(json_text)
        
    except Exception as e:
        st.error(f"Erro na API do Gemini. Verifique se a chave est√° correta ou o limite de uso foi atingido: {e}")
        return {"error": "Falha na gera√ß√£o do roteiro."}


# =========================================================================
# 3. INTERFACE STREAMLIT
# =========================================================================

def main():
    st.set_page_config(page_title="Video Maestro AI", layout="centered")
    st.title("üé¨ Video Maestro AI (Streamlit + Gemini + MoviePy)")
    st.markdown("---")

    # Verifica se a chave da API Gemini est√° configurada nos Secrets
    # Nota: st.secrets['CHAVE'] funciona apenas em Streamlit Cloud
    gemini_api_key = st.secrets.get("GEMINI_API_KEY")

    if not gemini_api_key:
        st.warning("‚ö†Ô∏è Chave GEMINI_API_KEY n√£o encontrada nos Streamlit Secrets.")
        st.markdown("Por favor, configure o `GEMINI_API_KEY` na se√ß√£o 'Secrets' do Streamlit Cloud.")
        st.stop()
            

    st.header("1. Ideia Central do V√≠deo")
    idea_central = st.text_area(
        "Descreva a ideia principal do v√≠deo (ex: 'O futuro da intelig√™ncia artificial no mercado de trabalho', 'Tr√™s li√ß√µes de grandes l√≠deres')",
        max_chars=200,
        height=100
    )

    if st.button("üöÄ Gerar e Renderizar V√≠deo Automatizado"):
        if not idea_central:
            st.error("Por favor, insira uma ideia central para come√ßar.")
            return

        # ----------------------------------------------------
        # ETAPA 1: GERA√á√ÉO DO ROTEIRO E BLUEPRINT (JSON)
        # ----------------------------------------------------
        st.subheader("2. Gera√ß√£o do Roteiro (IA)")
        script_data = generate_script_and_prompts(idea_central, gemini_api_key)

        if "error" in script_data:
            return
        
        st.success("Roteiro gerado com sucesso!")
        st.json(script_data)

        # ----------------------------------------------------
        # ETAPA 2 & 3: GERA√á√ÉO DE ASSETS E MONTAGEM DO CLIPE
        # ----------------------------------------------------
        st.subheader("3. Gera√ß√£o de Assets, TTS e Montagem")
        
        video_clips = []
        status_placeholder = st.empty()
        
        for scene in script_data.get("cenas", []):
            scene_id = scene["id"]
            narration = scene["texto_narra√ß√£o"]
            
            status_placeholder.info(f"Processando Cena {scene_id}: Gerando √Åudio e Imagem Placeholder...")

            # Gera√ß√£o de √Åudio (TTS)
            audio_path, duration = generate_tts_audio(scene_id, narration)
            
            if duration == 0.0:
                 st.warning(f"Cena {scene_id} pulada devido a erro de √°udio.")
                 continue

            # Gera√ß√£o de Imagem (Placeholder)
            image_path = create_placeholder_image(scene_id, narration)
            
            # Montagem do MoviePy
            
            # 3.1. Clipe de √Åudio
            audio_clip = mp_editor.AudioFileClip(audio_path)
            
            # 3.2. Clipe de Imagem (ajusta a dura√ß√£o para o √°udio)
            image_clip = mp_editor.ImageClip(image_path, duration=duration)
            
            # 3.3. Adi√ß√£o de Texto/Legenda
            text_clip = mp_editor.TextClip(
                narration, 
                fontsize=40, 
                color='yellow', 
                bg_color='black', 
                size=image_clip.size
            ).set_duration(duration)
            
            final_scene = image_clip.set_audio(audio_clip)
            
            # Define o clipe final com a sobreposi√ß√£o de texto
            final_scene = final_scene.set_duration(duration).set_overlay(
                text_clip.set_pos(("center", 0.8), relative=True).margin(bottom=15, opacity=0.8)
            )

            video_clips.append(final_scene)
        
        status_placeholder.empty()
        
        # ----------------------------------------------------
        # ETAPA 4: RENDERIZA√á√ÉO FINAL
        # ----------------------------------------------------
        st.subheader("4. Renderiza√ß√£o do V√≠deo Final")

        if not video_clips:
            st.error("Nenhum clipe foi gerado para renderizar.")
            return

        # Caminho tempor√°rio para o v√≠deo final
        final_video_path = os.path.join(tempfile.gettempdir(), "video_final.mp4")
        
        with st.spinner('‚è≥ Concatenando e Renderizando... Isso pode levar de 1 a 3 minutos dependendo do tamanho do v√≠deo.'):
            # Concatena todos os clipes de v√≠deo em sequ√™ncia
            final_clip = mp_editor.concatenate_videoclips(video_clips)
            
            # Renderiza o v√≠deo final
            final_clip.write_videofile(
                final_video_path, 
                codec='libx264', 
                audio_codec='aac', 
                fps=24, 
                verbose=False, 
                logger=None
            )
            
        st.success("‚úÖ V√≠deo Finalizado!")
        
        # ----------------------------------------------------
        # ETAPA 5: DOWNLOAD
        # ----------------------------------------------------
        
        # Exibe o player de v√≠deo
        st.video(final_video_path)
        
        # Oferece o arquivo para download
        with open(final_video_path, "rb") as file:
            st.download_button(
                label="‚¨áÔ∏è Baixar V√≠deo MP4",
                data=file,
                file_name="video_automatizado.mp4",
                mime="video/mp4"
            )

if __name__ == "__main__":
    # Garante que o diret√≥rio tempor√°rio exista antes de rodar o main
    os.makedirs(tempfile.gettempdir(), exist_ok=True)
    main()
