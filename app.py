import streamlit as st
import json
import os
import tempfile
import numpy as np
from PIL import Image, ImageDraw
from google import genai
from moviepy.editor import ImageClip, AudioFileClip, concatenate_audioclips, concatenate_videoclips, TextClip
from edge_tts import communicate # Biblioteca para Text-to-Speech

# =========================================================================
# 1. FUN√á√ïES DE GERA√á√ÉO (IA E TTS)
# =========================================================================

@st.cache_data
def create_placeholder_image(scene_id, text, width=1280, height=720):
    """
    Cria uma imagem de placeholder colorida no diret√≥rio tempor√°rio
    para simular o asset de imagem gerado por IA.
    """
    try:
        # Cria uma imagem colorida baseada no ID da cena
        color = (100 + scene_id * 20) % 255
        img = Image.new('RGB', (width, height), (color, 50, 80))
        draw = ImageDraw.Draw(img)

        # Adiciona o texto da cena
        font_color = (255, 255, 255)
        text_to_display = f"CENA {scene_id}\n\n{text}"
        
        # Simplesmente desenha o texto (o Streamlit n√£o lida bem com fontes complexas aqui)
        draw.text((50, 50), text_to_display, font=font_color) 

        # Salva o arquivo temporariamente
        temp_img_path = os.path.join(tempfile.gettempdir(), f"cena_{scene_id}.png")
        img.save(temp_img_path)
        return temp_img_path
    except Exception as e:
        st.error(f"Erro ao criar imagem placeholder: {e}")
        return None


def generate_tts_audio(scene_id, text_narration, voice="pt-BR-FranciscaNeural"):
    """
    Gera o arquivo de √°udio (narra√ß√£o) usando Edge-TTS e retorna o caminho e a dura√ß√£o.
    """
    temp_audio_path = os.path.join(tempfile.gettempdir(), f"audio_cena_{scene_id}.mp3")
    
    try:
        # Cria o comunicador TTS
        comm = communicate(text_narration, voice)
        
        # Salva o √°udio no arquivo tempor√°rio
        with open(temp_audio_path, "wb") as file:
            for chunk in comm:
                if chunk[0] == 2:
                    file.write(chunk[1])
        
        # Usa o MoviePy para determinar a dura√ß√£o exata do √°udio
        audio_clip = AudioFileClip(temp_audio_path)
        duration = audio_clip.duration
        audio_clip.close() 

        return temp_audio_path, duration
    
    except Exception as e:
        st.error(f"Erro ao gerar √°udio TTS: {e}")
        return None, 0.0


def generate_script_and_prompts(idea_central, gemini_api_key):
    """
    Usa a API do Gemini para gerar um roteiro estruturado no formato JSON.
    """
    
    # 1. Configura√ß√£o da API
    # O Streamlit acessa a chave de forma segura
    try:
        client = genai.Client(api_key=gemini_api_key)
    except Exception as e:
        st.error(f"Erro de inicializa√ß√£o da API Gemini: {e}. Verifique a chave em 'st.secrets'.")
        return {"error": "Falha na inicializa√ß√£o da API."}


    # 2. PROMPT DE ENGENHARIA (O cora√ß√£o da automa√ß√£o)
    prompt_instruction = f"""
    Voc√™ √© um roteirista profissional de v√≠deos curtos (YouTube Shorts) no estilo "Motivacional" ou "Curiosidades".
    O v√≠deo final deve ter no m√°ximo 45 segundos.

    A IDEIA CENTRAL do v√≠deo √©: "{idea_central}".

    Sua resposta deve ser estruturada em 3 a 5 Cenas, seguindo o FORMATO JSON estrito.
    N√£o adicione texto introdut√≥rio, explica√ß√µes ou qualquer conte√∫do fora do JSON.

    Para cada cena, gere TR√äS campos:
    1. "texto_narra√ß√£o": O texto exato (curto e envolvente) que ser√° falado.
    2. "duracao_segundos": O tempo de dura√ß√£o exato em segundos (entre 3.0 e 10.0) para esta cena.
    3. "prompt_imagem_ingles": Um prompt em INGL√äS, altamente descritivo e pronto para ser usado em um gerador de Imagens por IA (ex: Midjourney ou Stable Diffusion). O prompt deve ser ultra-realista e esteticamente agrad√°vel, e refletir exatamente o texto de narra√ß√£o.

    EXEMPLO DO FORMATO JSON (Use este modelo exatamente):

    {{
      "titulo_sugerido": "T√≠tulo chamativo aqui.",
      "cenas": [
        {{
          "id": 1,
          "texto_narra√ß√£o": "A jornada de mil milhas come√ßa com um √∫nico passo.",
          "duracao_segundos": 4.5,
          "prompt_imagem_ingles": "Cinematic shot of a lone traveler standing on a misty mountain path at sunrise, deep focus, epic, 8k, photorealistic."
        }}
        // ...
      ]
    }}
    """
    
    # 3. Chamada √† API
    try:
        with st.spinner('Gerando roteiro estruturado com Gemini...'):
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt_instruction,
                config={"response_mime_type": "application/json"}
            )
        
        # 4. Retorno
        return json.loads(response.text)
        
    except Exception as e:
        st.error(f"Erro na API do Gemini. Verifique se a chave est√° correta ou o limite de uso foi atingido: {e}")
        return {"error": "Falha na gera√ß√£o do roteiro."}


# =========================================================================
# 2. INTERFACE STREAMLIT
# =========================================================================

def main():
    st.set_page_config(page_title="Video Maestro AI", layout="centered")
    st.title("üé¨ Video Maestro AI (Streamlit + Gemini + MoviePy)")
    st.markdown("---")

    # Verifica se a chave da API Gemini est√° configurada nos Secrets
    gemini_api_key = st.secrets.get("GEMINI_API_KEY")

    if not gemini_api_key:
        st.warning("‚ö†Ô∏è Chave GEMINI_API_KEY n√£o encontrada nos Streamlit Secrets. Insira sua chave para continuar.")
        # Permite a entrada manual para testes em ambiente local
        gemini_api_key = st.text_input("Insira sua chave Gemini API aqui (Apenas para testes):", type="password")
        if not gemini_api_key:
            st.stop()
            

    st.header("1. Ideia Central do V√≠deo")
    idea_central = st.text_area(
        "Descreva a ideia principal do v√≠deo (ex: 'O futuro da intelig√™ncia artificial no mercado de trabalho', 'Tr√™s li√ß√µes de grandes l√≠deres')",
        max_chars=200,
        height=100
    )

    if st.button("üöÄ Gerar e Renderizar V√≠deo Automatizado"):
        if not idea_central:
            st.error("Por favor, insira uma ideia central para come√ßar.")
            return

        # ----------------------------------------------------
        # ETAPA 1: GERA√á√ÉO DO ROTEIRO E BLUEPRINT (JSON)
        # ----------------------------------------------------
        st.subheader("2. Gera√ß√£o do Roteiro (IA)")
        script_data = generate_script_and_prompts(idea_central, gemini_api_key)

        if "error" in script_data:
            return
        
        st.success("Roteiro gerado com sucesso!")
        st.json(script_data)

        # ----------------------------------------------------
        # ETAPA 2: GERA√á√ÉO DE ASSETS (√ÅUDIO E IMAGEM)
        # ----------------------------------------------------
        st.subheader("3. Gera√ß√£o de Assets e Clipes")
        
        video_clips = []
        status_placeholder = st.empty()
        
        for scene in script_data.get("cenas", []):
            scene_id = scene["id"]
            narration = scene["texto_narra√ß√£o"]
            
            status_placeholder.info(f"Processando Cena {scene_id}: Gerando √Åudio e Imagem Placeholder...")

            # Gera√ß√£o de √Åudio (TTS)
            audio_path, duration = generate_tts_audio(scene_id, narration)
            
            if duration == 0.0:
                 st.warning(f"Cena {scene_id} pulada devido a erro de √°udio.")
                 continue

            # Gera√ß√£o de Imagem (Placeholder, pois n√£o temos a API de Imagem aqui)
            # COMENT√ÅRIO: Aqui √© onde voc√™ integraria o DALL-E/Stability AI
            image_path = create_placeholder_image(scene_id, narration)
            
            # ----------------------------------------------------
            # ETAPA 3: MONTAGEM DO CLIPE (MoviePy)
            # ----------------------------------------------------
            
            # 3.1. Clipe de √Åudio
            audio_clip = AudioFileClip(audio_path)
            
            # 3.2. Clipe de Imagem (ajusta a dura√ß√£o para o √°udio)
            image_clip = ImageClip(image_path, duration=duration)
            
            # 3.3. Sincroniza√ß√£o e Adi√ß√£o de Texto Simples (Legenda)
            # Adiciona o texto da narra√ß√£o como legenda simples no centro
            text_clip = TextClip(
                narration, 
                fontsize=40, 
                color='yellow', 
                bg_color='black', 
                size=image_clip.size
            ).set_duration(duration)
            
            final_scene = image_clip.set_audio(audio_clip)
            
            # Combina a imagem com a legenda (posicionamento central, 80% do topo)
            final_scene = final_scene.set_duration(duration)
            
            # Se for adicionar texto como overlay:
            final_scene = final_scene.set_duration(duration).set_overlay(
                text_clip.set_pos(("center", 0.8), relative=True).margin(bottom=15, opacity=0.8)
            )

            video_clips.append(final_scene)
        
        status_placeholder.empty()
        
        # ----------------------------------------------------
        # ETAPA 4: RENDERIZA√á√ÉO FINAL
        # ----------------------------------------------------
        st.subheader("4. Renderiza√ß√£o do V√≠deo Final")

        if not video_clips:
            st.error("Nenhum clipe foi gerado para renderizar.")
            return

        final_video_path = os.path.join(tempfile.gettempdir(), "video_final.mp4")
        
        with st.spinner('‚è≥ Concatenando e Renderizando... Isso pode levar de 1 a 3 minutos dependendo do tamanho do v√≠deo.'):
            # Concatena todos os clipes de v√≠deo em sequ√™ncia
            final_clip = concatenate_videoclips(video_clips)
            
            # Renderiza o v√≠deo final
            final_clip.write_videofile(
                final_video_path, 
                codec='libx264', 
                audio_codec='aac', 
                fps=24, 
                verbose=False, 
                logger=None
            )
            
        st.success("‚úÖ V√≠deo Finalizado!")
        
        # ----------------------------------------------------
        # ETAPA 5: DOWNLOAD
        # ----------------------------------------------------
        
        # Exibe o player de v√≠deo
        st.video(final_video_path)
        
        # Oferece o arquivo para download
        with open(final_video_path, "rb") as file:
            st.download_button(
                label="‚¨áÔ∏è Baixar V√≠deo MP4",
                data=file,
                file_name="video_automatizado.mp4",
                mime="video/mp4"
            )

if __name__ == "__main__":
    # Garante que o diret√≥rio tempor√°rio exista
    os.makedirs(tempfile.gettempdir(), exist_ok=True)
    main()
